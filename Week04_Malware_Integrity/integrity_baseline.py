import hashlib
import csv
import time
from pathlib import Path

def sha256_file(path: Path, chunk_size=1 << 20) -> str:
    """Compute the SHA-256 hash of a file in chunks (efficient for large files)."""
    h = hashlib.sha256()
    with path.open('rb') as f:
        for chunk in iter(lambda: f.read(chunk_size), b''):
            h.update(chunk)
    return h.hexdigest()

def build_baseline(folder="sample_folder", out_csv="baseline.csv"):
    """
    Walk through all files in the target folder and record their SHA-256 hashes.
    The results are saved in a CSV file with filename, hash, and timestamp.
    """
    folder = Path(folder)
    rows = []
    now_iso = time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime())

    for p in sorted(folder.rglob("*")):
        if p.is_file():
            rows.append([str(p.relative_to(folder)), sha256_file(p), now_iso])

    out = Path(out_csv)
    out.parent.mkdir(parents=True, exist_ok=True)
    with out.open("w", newline="", encoding="utf-8") as f:
        w = csv.writer(f)
        w.writerow(["file", "sha256", "baseline_created_utc"])
        w.writerows(rows)

    print(f"Baseline saved: {out.resolve()} (files: {len(rows)})")

if __name__ == "__main__":
    build_baseline()
